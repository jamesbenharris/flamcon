{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff47479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-16 13:57:35,887] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from torch.distributed.fsdp import (\n",
    "    CPUOffload,\n",
    "    MixedPrecision,\n",
    "    ShardingStrategy,\n",
    "    BackwardPrefetch,\n",
    ")\n",
    "from torch import  nn, zeros, float32, float16, cuda, set_float32_matmul_precision, load, argmax, save, tile\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import RandomSampler,DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.flamcon import Flamcon, LayerNorm\n",
    "from src.distributed import init_distributed_device, world_info_from_env\n",
    "from src.misc import save_checkpoint\n",
    "from src.dataloader import WebVidDataset, RandomVideos\n",
    "\n",
    "\n",
    "from vit_pytorch.vit import ViT\n",
    "from vit_pytorch.extractor import Extractor\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from einops import rearrange\n",
    "from deepspeed.ops.adam import FusedAdam\n",
    "from deepspeed.ops.adam import DeepSpeedCPUAdam\n",
    "\n",
    "from labml_nn.sampling.nucleus import NucleusSampler\n",
    "from labml_nn.sampling.temperature import TemperatureSampler\n",
    "from labml.logger import Text\n",
    "\n",
    "\n",
    "set_float32_matmul_precision('medium')\n",
    "\n",
    "def tokenize(tokenizer,text):\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    text =  tokenizer(\n",
    "        text,\n",
    "        max_length=512,\n",
    "        padding=\"longest\",\n",
    "        truncation=\"only_first\",\n",
    "        return_tensors=\"pt\",\n",
    "    )   \n",
    "    return  text['input_ids'], text['attention_mask'].bool()\n",
    "\n",
    "def getLoss(predicted, labels, logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss between predicted and actual tokens.\n",
    "\n",
    "    Args:\n",
    "        predicted (Tensor): Predicted tokens.\n",
    "        actual (Tensor): Actual tokens.\n",
    "        logits (Callable): Function to compute logits.\n",
    "\n",
    "    Returns:\n",
    "        loss (Tensor): Cross-entropy loss.\n",
    "    \"\"\"\n",
    "    predicted = logits(predicted)[:,-labels.shape[1]:,:]\n",
    "    #predicted = rearrange(predicted, 'b n c -> b c n')\n",
    "    print(predicted.shape)\n",
    "    \n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    labels[labels == tokenizer.eos_token] = -100\n",
    "    labels[labels == tokenizer.encode(\"<media>\")[-1]] = -100\n",
    "        \n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    loss = 0\n",
    "    for i in range(len(predicted)):\n",
    "        losses = loss_fct(\n",
    "            predicted[i], labels[i]\n",
    "        )\n",
    "        loss+=losses\n",
    "    loss=loss/len(predicted)\n",
    "    return loss\n",
    "\n",
    "def generate(\n",
    "        model,\n",
    "        text,\n",
    "        tokenizer,\n",
    "        to_logits,\n",
    "        *,\n",
    "        images=None,\n",
    "        videos=None,\n",
    "        embeds=None,\n",
    "        gen=True,\n",
    "        attention_mask=None,\n",
    "        n_tokens = 100,\n",
    "        n_samples = 1\n",
    "        \n",
    "    ):\n",
    "        sampler = NucleusSampler(0.95, TemperatureSampler(1.))\n",
    "        data = torch.tile(text[None, :], (1, 1))[0]\n",
    "        logs = [[(text, Text.meta)] for _ in range(n_samples)]\n",
    "        seq_len = len(text)\n",
    "        for i in range(n_tokens):\n",
    "            data = data[-seq_len:]\n",
    "            output = model.forward(data,images=images,videos=videos,embeds=embeds,gen=gen,attention_mask=attention_mask)\n",
    "            logits = to_logits(output)\n",
    "            logits = logits[:, -1]\n",
    "            res = sampler(logits)\n",
    "            data = torch.cat([data, res.reshape(res.shape[0],1)], dim=1)\n",
    "#             for j in range(1):\n",
    "#                 logs[j] += [('' + tokenizer.decode(res.item()), Text.value)]\n",
    "        return data\n",
    "    \n",
    "def test(args, model, rank, dialogue, media, tokenizer, to_logits):\n",
    "    \"\"\"\n",
    "    Perform the training loop for one epoch.\n",
    "\n",
    "    Args:\n",
    "        args: Parsed command-line arguments.\n",
    "        model: The Flamcon model.\n",
    "        rank (int): Process rank.\n",
    "        dialog: tokens\n",
    "        media: image/video\n",
    "\n",
    "    Returns:\n",
    "        text_tokens: the output the prediction\n",
    "    \"\"\"\n",
    "    input_ids, attention_mask = tokenize(tokenizer,dialogue)\n",
    "    input_ids = input_ids.to(rank)\n",
    "    media = media.to(rank)\n",
    "    if args.video:\n",
    "        text_tokens = generate(model,input_ids, tokenizer, to_logits, videos=media)\n",
    "    else:\n",
    "        text_tokens = model.generate(input_ids, tokenizer, to_logits, images=media)\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5e8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    horovod=False\n",
    "    dist_backend=\"nccl\"\n",
    "    dist_url=\"env://\"\n",
    "    no_set_device_rank=False\n",
    "    cpu_offload=True\n",
    "    batch=2\n",
    "    dim=4544\n",
    "    num_tokena=65027\n",
    "    epochs=1\n",
    "    fsdp=True\n",
    "    video=True\n",
    "    max_frames=40\n",
    "    max_tokens=512\n",
    "    lang_model=\"tiiuae/falcon-7b\"\n",
    "    run_name=\"flamcon\"\n",
    "    my_group=None\n",
    "    delete_previous_checkpoint=True\n",
    "    resume=True\n",
    "args=Args()\n",
    "args.local_rank, args.rank, args.world_size = world_info_from_env()\n",
    "device_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca690cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    vit = ViT(\n",
    "        image_size = 256,\n",
    "        patch_size = 32,\n",
    "        num_classes = 1000,\n",
    "        dim = args.dim,\n",
    "        depth = 6,\n",
    "        heads = 16,\n",
    "        mlp_dim = 2048,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "    vit = Extractor(vit, return_embeddings_only = True).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8131a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Falcon\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fbb5a740924cf4bc493d21fd6f9a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 65027. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flamcon\n",
      "ViT parameter num: 242355496 on rank 0\n",
      "\n",
      "Language parameter num: 6921734336 on rank 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    if args.rank == 0:\n",
    "        print(\"Loading Falcon\\n\")\n",
    "        \n",
    "    #Loads language model\n",
    "    falcon = AutoModelForCausalLM.from_pretrained(\n",
    "                args.lang_model,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.lang_model)\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"<|endofchunk|>\", \"<media>\"]}\n",
    "    )\n",
    "    tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "    falcon.resize_token_embeddings(new_num_tokens=len(tokenizer))\n",
    "    \n",
    "    #set Mixes precision policy\n",
    "    mp_policy = MixedPrecision(\n",
    "        param_dtype=float32,\n",
    "        reduce_dtype=float16,  # gradient communication\n",
    "        buffer_dtype=float16,\n",
    "    )\n",
    "\n",
    "    if args.rank == 0:\n",
    "        print(\"Loading Flamcon\")\n",
    "    \n",
    "    #Print parameters per GPU\n",
    "    print(f\"ViT parameter num: {sum(p.numel() for p in vit.parameters())} on rank {args.rank}\\n\")\n",
    "    print(f\"Language parameter num: {sum(p.numel() for p in falcon.parameters())} on rank {args.rank}\\n\")\n",
    "    to_logits = falcon.lm_head.to(args.rank)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380bf883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint flamcon/checkpoint_1.pt for run flamcon.\n",
      "\n",
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "    model = Flamcon(\n",
    "                    num_tokens = len(tokenizer),       # number of tokens\n",
    "                    dim = args.dim,                     # dimensions\n",
    "                    depth = 32,                         # depth\n",
    "                    heads = 8,                          # attention heads\n",
    "                    dim_head = 64,                      # dimension per attention head\n",
    "                    img_encoder = vit,                  # plugin your image encoder (this can be optional if you pass in the image embeddings \n",
    "                    media_token_id = tokenizer.encode(\"<media>\")[-1],                 # the token id representing the [media] or [image]\n",
    "                    cross_attn_every = 3,               # how often to cross attend\n",
    "                    perceiver_num_latents = 64,         # perceiver number of latents, should be smaller than the sequence length of the image tokens\n",
    "                    perceiver_depth = 2,                # perceiver resampler depth\n",
    "                    max_video_frames = args.max_frames, # max video frames\n",
    "                    lang_model = falcon                 # llm\n",
    "                    )\n",
    "\n",
    "    del vit\n",
    "    del falcon\n",
    "    resume_from_epoch = 0\n",
    "    checkpoint = None\n",
    "    if os.path.exists(f\"{args.run_name}\") and args.resume:\n",
    "        checkpoint_list = glob.glob(f\"{args.run_name}/checkpoint_*.pt\")\n",
    "        if len(checkpoint_list) == 0:\n",
    "            print(f\"Found no checkpoints for run {args.run_name}.\\n\")\n",
    "        else:\n",
    "            resume_from_checkpoint = sorted(\n",
    "                checkpoint_list, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])\n",
    "            )[-1]\n",
    "            print(\n",
    "                f\"Found checkpoint {resume_from_checkpoint} for run {args.run_name}.\\n\"\n",
    "            )\n",
    "            checkpoint = load(resume_from_checkpoint, map_location=\"cpu\")\n",
    "            resume_from_epoch = checkpoint[\"epoch\"] + 1\n",
    "            if args.rank == 0:\n",
    "                model.load_state_dict(checkpoint[\"model_state_dict\"], False)\n",
    "    print('Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577f7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0958a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WebVidDataset(\"test_nw.csv\",\"data\",args.max_frames,tokenizer,args.max_tokens,test=True,samples=48)\n",
    "sampler = DistributedSampler(data, rank=args.rank, num_replicas=args.world_size, shuffle=True)\n",
    "dataloader = DataLoader(data,batch_size=6,sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5ebcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ?, ?it/s]\u001b[0m\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (6, 65027)) of distribution Categorical(logits: torch.Size([6, 65027])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m media, X, y, file, \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      3\u001b[0m media \u001b[38;5;241m=\u001b[39m media\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmedia\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(file[\u001b[38;5;241m0\u001b[39m],text)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 135\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(args, model, rank, dialogue, media, tokenizer, to_logits)\u001b[0m\n\u001b[1;32m    133\u001b[0m media \u001b[38;5;241m=\u001b[39m media\u001b[38;5;241m.\u001b[39mto(rank)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mvideo:\n\u001b[0;32m--> 135\u001b[0m     text_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmedia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     text_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids, tokenizer, to_logits, images\u001b[38;5;241m=\u001b[39mmedia)\n",
      "Cell \u001b[0;32mIn[1], line 111\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, text, tokenizer, to_logits, images, videos, embeds, gen, attention_mask, n_tokens, n_samples)\u001b[0m\n\u001b[1;32m    109\u001b[0m             logits \u001b[38;5;241m=\u001b[39m to_logits(output)\n\u001b[1;32m    110\u001b[0m             logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 111\u001b[0m             res \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m             data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([data, res\u001b[38;5;241m.\u001b[39mreshape(res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#             for j in range(1):\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#                 logs[j] += [('' + tokenizer.decode(res.item()), Text.value)]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/labml_nn/sampling/nucleus.py:72\u001b[0m, in \u001b[0;36mNucleusSampler.__call__\u001b[0;34m(self, logits)\u001b[0m\n\u001b[1;32m     69\u001b[0m sorted_log_probs[\u001b[38;5;241m~\u001b[39mnucleus] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Sample from the sampler\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m sampled_sorted_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_log_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Get the actual indexes\u001b[39;00m\n\u001b[1;32m     75\u001b[0m res \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sampled_sorted_indexes\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/labml_nn/sampling/temperature.py:41\u001b[0m, in \u001b[0;36mTemperatureSampler.__call__\u001b[0;34m(self, logits)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mSample from logits\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Create a categorical distribution with temperature adjusted logits\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Sample\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dist\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/categorical.py:66\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter logits (Tensor of shape (6, 65027)) of distribution Categorical(logits: torch.Size([6, 65027])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "for batchid, data in enumerate(tqdm(dataloader,position=0, desc=\"Iters\", leave=False, colour='green', ncols=80)):\n",
    "    media, X, y, file, = data\n",
    "    media = media.to('cuda')\n",
    "    text = test(args, model, args.rank, X, media, tokenizer, to_logits)\n",
    "    print(file[0],text)\n",
    "    print('\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2069ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35.7711, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "    predicted = to_logits(text_tokens)[:,-input_ids_test.shape[1]:,:]\n",
    "    #predicted = rearrange(predicted, 'b n c -> b c n')    \n",
    "    input_ids_test[input_ids_test == tokenizer.pad_token_id] = -100\n",
    "    input_ids_test[input_ids_test == tokenizer.eos_token] = -100\n",
    "    input_ids_test[input_ids_test == tokenizer.encode(\"<media>\")[-1]] = -100\n",
    "        \n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    losses = 0\n",
    "    for i in range(len(predicted)):\n",
    "        loss = loss_fct(\n",
    "            predicted[i], input_ids_test[i]\n",
    "        )\n",
    "        losses+=loss\n",
    "    losses=losses/len(predicted)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67a3c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1003,  1003],\n",
       "        [ 8801, 31920],\n",
       "        [11060, 14560],\n",
       "        [ 8801, 31920],\n",
       "        [ 8801,  8801],\n",
       "        [31920, 31920]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "264c2ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD><PAD>',\n",
       " '<PAD><PAD>',\n",
       " 'woman sitting',\n",
       " '<PAD><PAD>',\n",
       " '<PAD><PAD>',\n",
       " '<PAD><PAD>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(input_ids[:,-input_ids_test.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23744b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' beingcurrent',\n",
       " 'beingdoing',\n",
       " '© outdoors',\n",
       " 'doingdoing',\n",
       " 'beingbeing',\n",
       " 'doingdoing']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(sampler(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2e4e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n",
      "torch.Size([6, 2, 65027])\n",
      "tensor(35.7711, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask = tokenize(tokenizer,X)\n",
    "input_ids = input_ids.to(args.rank)\n",
    "input_ids_test, attention_mask = tokenize(tokenizer,y)\n",
    "input_ids_test = input_ids_test.to(args.rank)\n",
    "sampler = NucleusSampler(0.95, TemperatureSampler(1.))\n",
    "input_ids = torch.tile(input_ids[None, :], (1, 1))[0]\n",
    "logs = [[(X, Text.meta)] for _ in range(1)]\n",
    "seq_len = len(X)\n",
    "for i in range(25):\n",
    "    text_tokens = model.forward(input_ids,videos=media,gen=True,attention_mask=attention_mask)\n",
    "    loss = getLoss(text_tokens, input_ids_test, to_logits, tokenizer)\n",
    "    print(loss)\n",
    "#     logits = to_logits(output)\n",
    "#     logits = logits[:, -1, :]\n",
    "#     res = sampler(logits)\n",
    "#     #print(tokenizer.batch_decode(res,skip_special_tokens=True))\n",
    "#     input_ids = torch.cat([input_ids, res], dim=1)\n",
    "    #for j in range(1):\n",
    "        #logs[j] += [('' + tokenizer.decode(res.item()), Text.value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "245bc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f211947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepWebVid(data):\n",
    "    rows = []\n",
    "    for idx,row in data.iterrows():\n",
    "        text = re.findall(r\"[\\w']+|[.,!?;]\",row[\"name\"]) \n",
    "        for i in range(len(text)-1):\n",
    "            rw = row.copy()\n",
    "            rw['X'] = ' '.join(text[:i+1])\n",
    "            rw['y'] = text[i+1]\n",
    "            rows.append(rw)\n",
    "    rows = pd.DataFrame(rows)\n",
    "    rows.reset_index()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa922b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train = train.drop('Unnamed: 0',axis=1)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test = test.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167cd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepWebVid(train)\n",
    "train.to_csv('data/train_nw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a74f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepWebVid(test)\n",
    "test.to_csv('data/test_nw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9912d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_nw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8e2c727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>videoid</th>\n",
       "      <th>contentUrl</th>\n",
       "      <th>duration</th>\n",
       "      <th>page_dir</th>\n",
       "      <th>name</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26431865</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/26431...</td>\n",
       "      <td>PT00H00M10S</td>\n",
       "      <td>143201_143250</td>\n",
       "      <td>In a modern private office young male and fema...</td>\n",
       "      <td>In</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26431865</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/26431...</td>\n",
       "      <td>PT00H00M10S</td>\n",
       "      <td>143201_143250</td>\n",
       "      <td>In a modern private office young male and fema...</td>\n",
       "      <td>In a</td>\n",
       "      <td>modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26431865</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/26431...</td>\n",
       "      <td>PT00H00M10S</td>\n",
       "      <td>143201_143250</td>\n",
       "      <td>In a modern private office young male and fema...</td>\n",
       "      <td>In a modern</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26431865</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/26431...</td>\n",
       "      <td>PT00H00M10S</td>\n",
       "      <td>143201_143250</td>\n",
       "      <td>In a modern private office young male and fema...</td>\n",
       "      <td>In a modern private</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26431865</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/26431...</td>\n",
       "      <td>PT00H00M10S</td>\n",
       "      <td>143201_143250</td>\n",
       "      <td>In a modern private office young male and fema...</td>\n",
       "      <td>In a modern private office</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9779</th>\n",
       "      <td>499</td>\n",
       "      <td>1012328408</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10123...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>012451_012500</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk, broke...</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk , broken</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9780</th>\n",
       "      <td>499</td>\n",
       "      <td>1012328408</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10123...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>012451_012500</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk, broke...</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk , brok...</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9781</th>\n",
       "      <td>499</td>\n",
       "      <td>1012328408</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10123...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>012451_012500</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk, broke...</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk , brok...</td>\n",
       "      <td>abandoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9782</th>\n",
       "      <td>499</td>\n",
       "      <td>1012328408</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10123...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>012451_012500</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk, broke...</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk , brok...</td>\n",
       "      <td>building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783</th>\n",
       "      <td>499</td>\n",
       "      <td>1012328408</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10123...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>012451_012500</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk, broke...</td>\n",
       "      <td>Donbass ukraine 2018 ruins of the kiosk , brok...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9784 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     videoid  \\\n",
       "0              0    26431865   \n",
       "1              0    26431865   \n",
       "2              0    26431865   \n",
       "3              0    26431865   \n",
       "4              0    26431865   \n",
       "...          ...         ...   \n",
       "9779         499  1012328408   \n",
       "9780         499  1012328408   \n",
       "9781         499  1012328408   \n",
       "9782         499  1012328408   \n",
       "9783         499  1012328408   \n",
       "\n",
       "                                             contentUrl     duration  \\\n",
       "0     https://ak.picdn.net/shutterstock/videos/26431...  PT00H00M10S   \n",
       "1     https://ak.picdn.net/shutterstock/videos/26431...  PT00H00M10S   \n",
       "2     https://ak.picdn.net/shutterstock/videos/26431...  PT00H00M10S   \n",
       "3     https://ak.picdn.net/shutterstock/videos/26431...  PT00H00M10S   \n",
       "4     https://ak.picdn.net/shutterstock/videos/26431...  PT00H00M10S   \n",
       "...                                                 ...          ...   \n",
       "9779  https://ak.picdn.net/shutterstock/videos/10123...  PT00H00M11S   \n",
       "9780  https://ak.picdn.net/shutterstock/videos/10123...  PT00H00M11S   \n",
       "9781  https://ak.picdn.net/shutterstock/videos/10123...  PT00H00M11S   \n",
       "9782  https://ak.picdn.net/shutterstock/videos/10123...  PT00H00M11S   \n",
       "9783  https://ak.picdn.net/shutterstock/videos/10123...  PT00H00M11S   \n",
       "\n",
       "           page_dir                                               name  \\\n",
       "0     143201_143250  In a modern private office young male and fema...   \n",
       "1     143201_143250  In a modern private office young male and fema...   \n",
       "2     143201_143250  In a modern private office young male and fema...   \n",
       "3     143201_143250  In a modern private office young male and fema...   \n",
       "4     143201_143250  In a modern private office young male and fema...   \n",
       "...             ...                                                ...   \n",
       "9779  012451_012500  Donbass ukraine 2018 ruins of the kiosk, broke...   \n",
       "9780  012451_012500  Donbass ukraine 2018 ruins of the kiosk, broke...   \n",
       "9781  012451_012500  Donbass ukraine 2018 ruins of the kiosk, broke...   \n",
       "9782  012451_012500  Donbass ukraine 2018 ruins of the kiosk, broke...   \n",
       "9783  012451_012500  Donbass ukraine 2018 ruins of the kiosk, broke...   \n",
       "\n",
       "                                                      X          y  \n",
       "0                                                    In          a  \n",
       "1                                                  In a     modern  \n",
       "2                                           In a modern    private  \n",
       "3                                   In a modern private     office  \n",
       "4                            In a modern private office      young  \n",
       "...                                                 ...        ...  \n",
       "9779   Donbass ukraine 2018 ruins of the kiosk , broken    windows  \n",
       "9780  Donbass ukraine 2018 ruins of the kiosk , brok...          ,  \n",
       "9781  Donbass ukraine 2018 ruins of the kiosk , brok...  abandoned  \n",
       "9782  Donbass ukraine 2018 ruins of the kiosk , brok...   building  \n",
       "9783  Donbass ukraine 2018 ruins of the kiosk , brok...          .  \n",
       "\n",
       "[9784 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['videoid'].isin(train_df['videoid'].unique()[:500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a1e5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_nw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03089915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>videoid</th>\n",
       "      <th>contentUrl</th>\n",
       "      <th>duration</th>\n",
       "      <th>page_dir</th>\n",
       "      <th>name</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1032280022</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10322...</td>\n",
       "      <td>PT00H00M32S</td>\n",
       "      <td>070301_070350</td>\n",
       "      <td>Young man and woman working out outdoors in th...</td>\n",
       "      <td>Young</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1032280022</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10322...</td>\n",
       "      <td>PT00H00M32S</td>\n",
       "      <td>070301_070350</td>\n",
       "      <td>Young man and woman working out outdoors in th...</td>\n",
       "      <td>Young man</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1032280022</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10322...</td>\n",
       "      <td>PT00H00M32S</td>\n",
       "      <td>070301_070350</td>\n",
       "      <td>Young man and woman working out outdoors in th...</td>\n",
       "      <td>Young man and</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1032280022</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10322...</td>\n",
       "      <td>PT00H00M32S</td>\n",
       "      <td>070301_070350</td>\n",
       "      <td>Young man and woman working out outdoors in th...</td>\n",
       "      <td>Young man and woman</td>\n",
       "      <td>working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1032280022</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10322...</td>\n",
       "      <td>PT00H00M32S</td>\n",
       "      <td>070301_070350</td>\n",
       "      <td>Young man and woman working out outdoors in th...</td>\n",
       "      <td>Young man and woman working</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>49</td>\n",
       "      <td>1019991253</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10199...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>078651_078700</td>\n",
       "      <td>Venice, italy, 1974, palazzo, ca' rezonica, in...</td>\n",
       "      <td>Venice , italy , 1974 , palazzo , ca' rezonica...</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>49</td>\n",
       "      <td>1019991253</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10199...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>078651_078700</td>\n",
       "      <td>Venice, italy, 1974, palazzo, ca' rezonica, in...</td>\n",
       "      <td>Venice , italy , 1974 , palazzo , ca' rezonica...</td>\n",
       "      <td>ceiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>49</td>\n",
       "      <td>1019991253</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10199...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>078651_078700</td>\n",
       "      <td>Venice, italy, 1974, palazzo, ca' rezonica, in...</td>\n",
       "      <td>Venice , italy , 1974 , palazzo , ca' rezonica...</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>49</td>\n",
       "      <td>1019991253</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10199...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>078651_078700</td>\n",
       "      <td>Venice, italy, 1974, palazzo, ca' rezonica, in...</td>\n",
       "      <td>Venice , italy , 1974 , palazzo , ca' rezonica...</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>49</td>\n",
       "      <td>1019991253</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10199...</td>\n",
       "      <td>PT00H00M11S</td>\n",
       "      <td>078651_078700</td>\n",
       "      <td>Venice, italy, 1974, palazzo, ca' rezonica, in...</td>\n",
       "      <td>Venice , italy , 1974 , palazzo , ca' rezonica...</td>\n",
       "      <td>tiepolo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     videoid  \\\n",
       "0             0  1032280022   \n",
       "1             0  1032280022   \n",
       "2             0  1032280022   \n",
       "3             0  1032280022   \n",
       "4             0  1032280022   \n",
       "..          ...         ...   \n",
       "987          49  1019991253   \n",
       "988          49  1019991253   \n",
       "989          49  1019991253   \n",
       "990          49  1019991253   \n",
       "991          49  1019991253   \n",
       "\n",
       "                                            contentUrl     duration  \\\n",
       "0    https://ak.picdn.net/shutterstock/videos/10322...  PT00H00M32S   \n",
       "1    https://ak.picdn.net/shutterstock/videos/10322...  PT00H00M32S   \n",
       "2    https://ak.picdn.net/shutterstock/videos/10322...  PT00H00M32S   \n",
       "3    https://ak.picdn.net/shutterstock/videos/10322...  PT00H00M32S   \n",
       "4    https://ak.picdn.net/shutterstock/videos/10322...  PT00H00M32S   \n",
       "..                                                 ...          ...   \n",
       "987  https://ak.picdn.net/shutterstock/videos/10199...  PT00H00M11S   \n",
       "988  https://ak.picdn.net/shutterstock/videos/10199...  PT00H00M11S   \n",
       "989  https://ak.picdn.net/shutterstock/videos/10199...  PT00H00M11S   \n",
       "990  https://ak.picdn.net/shutterstock/videos/10199...  PT00H00M11S   \n",
       "991  https://ak.picdn.net/shutterstock/videos/10199...  PT00H00M11S   \n",
       "\n",
       "          page_dir                                               name  \\\n",
       "0    070301_070350  Young man and woman working out outdoors in th...   \n",
       "1    070301_070350  Young man and woman working out outdoors in th...   \n",
       "2    070301_070350  Young man and woman working out outdoors in th...   \n",
       "3    070301_070350  Young man and woman working out outdoors in th...   \n",
       "4    070301_070350  Young man and woman working out outdoors in th...   \n",
       "..             ...                                                ...   \n",
       "987  078651_078700  Venice, italy, 1974, palazzo, ca' rezonica, in...   \n",
       "988  078651_078700  Venice, italy, 1974, palazzo, ca' rezonica, in...   \n",
       "989  078651_078700  Venice, italy, 1974, palazzo, ca' rezonica, in...   \n",
       "990  078651_078700  Venice, italy, 1974, palazzo, ca' rezonica, in...   \n",
       "991  078651_078700  Venice, italy, 1974, palazzo, ca' rezonica, in...   \n",
       "\n",
       "                                                     X         y  \n",
       "0                                                Young       man  \n",
       "1                                            Young man       and  \n",
       "2                                        Young man and     woman  \n",
       "3                                  Young man and woman   working  \n",
       "4                          Young man and woman working       out  \n",
       "..                                                 ...       ...  \n",
       "987  Venice , italy , 1974 , palazzo , ca' rezonica...         ,  \n",
       "988  Venice , italy , 1974 , palazzo , ca' rezonica...   ceiling  \n",
       "989  Venice , italy , 1974 , palazzo , ca' rezonica...  painting  \n",
       "990  Venice , italy , 1974 , palazzo , ca' rezonica...         ,  \n",
       "991  Venice , italy , 1974 , palazzo , ca' rezonica...   tiepolo  \n",
       "\n",
       "[992 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['videoid'].isin(test_df['videoid'].unique()[:50])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
